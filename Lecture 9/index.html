<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content=
      "width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Computational Physics Lecture 9</title>
    <link rel="stylesheet" href="../dist/reset.css">
    <link rel="stylesheet" href="../dist/reveal.css">
    <link rel="stylesheet" href="../dist/theme/serif.css"
      id="theme">
    <!-- <link rel="stylesheet" href="./dist/theme/night.css" id="theme"> -->
    <!-- Theme used for syntax highlighted code -->
    <link rel="stylesheet" href=
      "../plugin/highlight/monokai.css" id="highlight-theme">
    <link rel="stylesheet" href=
      "../css/style.css">
  </head>
  <body>
    <div class="reveal">
      <div class="slides">
        <section>
          <h2>Ordinary Differential Equations</h2>
        </section>

        <section>
          <h2>Adaptive DP45</h2>
          <p>Recall the prescription for adaptive Dormand-Prince Runge-Kutta 5(4)th order method:</p>
          <ol>
            <li class="fragment">Compute $y^{(1)}$ and $y^{(2)}$ using the two different rows of
              the DP45 Butcher Tableau. Remember $y$ might be a vector, especially when we solve multiple coupled equations at once.</li>
            <li class="fragment">Compute the error estimate for each component $\varepsilon_i = |y_i^{(1)} - y_i^{(2)}|$ and target error $\varepsilon_\mathrm{target,i} = \epsilon_\mathrm{abs} + \epsilon_\mathrm{rel} |y_i^{(1)}|$.</li>
            <div class="fragment">
              <li>Compute the rescaled scalar error, $N_\mathrm{eq}$ is the number of equations, or number of components of $\mathbf{y}$:</li>
              $$
              \mathrm{err} = \sqrt{\frac{1}{N_\mathrm{eq}}\sum_{i=0}^{N_\mathrm{eq} - 1} \left(\frac{\varepsilon_i}{\varepsilon_\mathrm{target,i}}\right)^2}
              $$
            </div>
            <li class="fragment">
              If $\mathrm{err} < 1$, accept the step and move forward by
              advancing $x\to x+h$. Otherwise, reject the step and try again.
              Either way, we can set $h' = Sh/(\mathrm{err})^{1/5}$. If $\mathrm{err}
              < 1$, this step will increase the step size at next step.
            </li>
          </ol>
        </section>

        <section>
          <h2>Dense Output</h2>
          <p>One challenge of an adaptive integration method is that you often
            can't predict where the points will be located. It becomes annoying when you
            want to evaluate the unknown function at some exact point $x$.</p>
          <p class="fragment">Dense output is a way to carry out interpolation
            as the integration goes on. It can make use of estimates of the
            derivative $k_i$ during the integration to do interpolation, making it
            more accurate and efficient.</p>
        </section>

        <section>
          <h2>Dense Output</h2>
          <p>For example, say you would like to evaluate the unknown function at
            $x = x_n + \theta h$, where $0&lt;\theta&lt;1$. One can use an
            interpolation polynomial such as:
            $$
            y(x_n + \theta h) = (1 - \theta) y_n + \theta y_{n+1}
            $$
          </p>
          <p class="fragment">
            This is a linear interpolation, which is 1st order accurate. It
            doesn't use any information about the derivatives at the endpoints.
        </section>
        <section>
          <h2>Dense Output</h2>
          <p>This is an example of a higher order interpolation polynomial that makes
            use of the derivatives at the endpoints:</p>
          $$
          \begin{split}
          y(x_n + \theta h) &= (1-\theta)y_n + \theta y_{n+1} + \\
          &\quad \theta(\theta - 1)\left[(1 - 2\theta)(y_{n+1} - y_n) + (\theta - 1)hf_n + \theta h f_{n+1}\right]
          \end{split}
          $$
          <p class="fragment">
            This gives a 3rd order interpolation polynomial. The coefficients
            are known during the integration, so it's easy to evaluate the
            function at any point between $x_n$ and $x_{n+1}$.
          </p>
        </section>

        <section>
          <h2>Dense Output</h2>
          <p>For the Dormand-Prince method, a 4th order interpolation method can
            be implemented using the intermediate derivatives $k_i$:</p>
          $$
          \mathbf{y}(x_n + \theta h) = \mathbf{r}_1 + \theta(\mathbf{r}_2 + (1 - \theta)(\mathbf{r}_3 + \theta(\mathbf{r}_4 + (1 - \theta) \mathbf{r}_5)))
          $$
          <p class="fragment">
            where
            $$
            \begin{split}
            \mathbf{r}_1 &= \mathbf{y}_n,\quad \mathbf{r}_2 = \mathbf{y}_{n+1} - \mathbf{y}_n, \\
            \mathbf{r}_3 &= \mathbf{y}_n + h\mathbf{k}_1 - \mathbf{y}_{n+1},\quad \mathbf{r}_4 = 2(\mathbf{y}_{n+1} - \mathbf{y}_n) - h(\mathbf{k}_1 + \mathbf{k}_7), \\
            \mathbf{r}_5 &= h(d_1 \mathbf{k}_1 + d_3 \mathbf{k}_3 + d_4 \mathbf{k}_4 + d_5 \mathbf{k}_5 + d_6 \mathbf{k}_6 + d_7 \mathbf{k}_7)
            \end{split}
            $$
          </p>
        </section>

        <section>
          <h2>Dense Output</h2>
          <p>The $d_i$ coefficients for the DP45 method are:
            $$
            \begin{split}
            d1 &= -12715105075.0/11282082432.0, \\
            d3 &= 87487479700.0/32700410799.0, \\
            d4 &= -10690763975.0/1880347072.0, \\
            d5 &= 701980252875.0/199316789632.0, \\
            d6 &= -1453857185.0/822651844.0, \\
            d7 &= 69997945.0/29380423.0
            \end{split}
            $$
          </p>
        </section>

        <section>
          <h2>Dense Output</h2>
          <p>When implementing dense output, the <code>integrate</code> method
            needs to be given an array of points $\{x_i\}$ where we want the
            results to be evaluated. Then, at each integration step, after we
            decided to keep the result, we go through the points in $\{x_i\}$ that
            lie between $x_n$ and $x_{n+1}$. For each point, we evaluate the
            intermediate values $y(x)$ using the interpolation polynomial.</p>
        </section>

        <section>
          <h2>Dense Output</h2>
          <p>Embedded methods such as DP45 often comes with a native interpolation scheme that
            is as accurate as the lower order estimate, using the derivatives evaluated in the
            intermediate steps.</p>
        </section>

        <section>
          <h2>Stop Condition</h2>
          <p>So far, we have not discuss when to end the integration. The simplest way is starting from
          $x_0$, and integrate until you hit $x_\mathrm{end}$.</p>
          <p class="fragment">However, there are many situations where you don't know exactly
          where to stop. For example, you might be integrating a trajectory of an object, and
          you want to stop when it hits the ground, but it's not known in advance where that will be.</p>
          <div class="fragment">
            <p>It is good practice to implement a custom stop condition and pass it
            to the integrator. The integrator will check the stop condition at each successful step,
            and stop if the condition is met.</p>
            <div style="width: 90%; margin: auto;">
              <pre><code class="language-c++" data-trim data-noescape>
// Example of a stop condition that stops when y[1] (height) goes below 0
auto stop_condition = [](double x, const std::vector&lt;double&gt;&amp; y) {
  return y[1] &lt;= 0;
};
              </code></pre>
            </div>
          </div>
        </section>

        <section>
          <h2>Embedded Dormand-Prince 8th Order</h2>
          <p>There is an even better version of the Dormand-Prince method that
            has 8th order accuracy with 12 evaluations of $f$. It has two
            embedded methods, one 5th order and one 3rd order. The coefficients of this method
            are included in an appendix of Numerical Recipes (3rd Edition).</p>
          <p>The error estimate is:</p>
          $$
          \mathrm{err} = \mathrm{err_5}\frac{\mathrm{err_5}}{\sqrt{0.01(\mathrm{err_3})^2 + (\mathrm{err_5})^2}}
          $$
          <p>This is often called the 853 method, and implemented in most
            software packages. For example, there is <code>scipy.integrate.DOP853</code>.</p>
          <p class="fragment">The method uses a combination of the 3 different estimates to
            construct a 7th order interpolation for dense output.</p>
        </section>

        <section>
          <h2>Project 1</h2>
          <img data-src="gr-for-babies.jpg"
            style="display: inline-block; width: 50%;">
        </section>

        <section>
          <h2>Parallel Programming</h2>
          <p>Modern CPUs have multiple cores. How to make use of them?</p>
          <img src="multi-core.webp" width="60%">
        </section>

        <section>
          <h2>Parallel Programming</h2>
          <p>There are different levels of parallelization:</p>
          <ul>
            <li class="fragment">Same operations on a set of different data on the same CPU core.
            This is called "vectorization".</li>
            <li class="fragment">Multiple CPU cores on the same machine. All
            cores share access to the same system memory.</li>
            <li class="fragment">Multiple machines on the same network. Each machine has their
              own exclusive memory.
          </ul>
        </section>

        <section>
          <h2>Vectorization</h2>
          <p>Vectorization used to be called "SIMD" (Same Instruction Multiple Data).
          Depending on the CPU instruction set, it can work on a set of floating
          point numbers at the same time. For example, the Intel AVX-512 instruction set
            has the following intrinsic functions:</p>
          <div class="fragment">
            <code>__m512d _mm512_load_pd (void const* mem_addr)</code>
          </div>
          <div class="fragment">
            <code>__m512d _mm512_add_pd (__m512d a, __m512d b)</code>
          </div>
          <div class="fragment">
            <code>void _mm512_store_pd (void* mem_addr, __m512d a)</code>
          </div>
          <p class="fragment">You can find the official guide <a href="https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html">here</a>.</p>
        </section>

        <section>
          <h2>Vectorization</h2>
          <p>Vectorization is now often done automatically by the compiler. Simple <code>for</code>
            loops often can be automatically be vectorized. This is partly what
            makes code compiled with the <code>-O3</code> flag significantly faster.</p>
          <p class="fragment">
            For very specific applications, you may need to write the intrinsics
            directly. Such level of fine-tuning can be very challenging.
          </p>
        </section>

        <section>
          <h2>Shared Memory Parallelization</h2>
          <p>For parallelization over multiple CPU cores on the same machine, a
          model using "threads" is often used.</p>
          <p class="fragment">
            Each thread executes its instructions sequentially. Everything you have written in
            this course has been single-threaded.
          </p>
          <p class="fragment">
            With Hyperthreading, each modern CPU core can technically execute up to 2
            threads simultaneously. However, when the workload of each thread is high,
            each physical core will be saturated by one thread. It is better to use the
            full capacity of each core by using one thread per core.
          </p>
        </section>

        <section>
          <h2>Shared Memory Parallelization</h2>
          <p>There are 2 main ways to achieve multi-threading in C++:</p>
          <ul>
            <li class="fragment">
              <a href="https://en.cppreference.com/w/cpp/thread/thread">std::thread</a>
              is a built-in C++ library for multi-threading. Other threading
              libraries exist too. This is a "low-level" way to do manual
              multi-threading.
            </li>
            <li class="fragment">
              <a href="https://www.openmp.org/">OpenMP</a> is a set of compiler directives
              that can parallelize code automatically. This is a "high-level" way to
              do multi-threading.
            </li>
          </ul>
        </section>

        <section>
          <h2>OpenMP</h2>
          <p>OpenMP is a set of compiler directives that can parallelize code automatically.</p>
          <div style="width: 90%; margin: auto;">
            <pre><code class="language-c++" data-trim data-noescape>
#include &lt;print&gt;
#include &lt;omp.h&gt;

int main() {
#pragma omp parallel for
  for (int i = 0; i < 10; i++) {
    std::println("{}", i);
  }
  return 0;
}
            </code></pre>
          </div>
          <p class="fragment">This needs to be compiled with the <code>-fopenmp</code> flag.</p>
        </section>

        <section>
          <h2>OpenMP</h2>
          <p>A possible output of the above program is:</p>
          <div style="width: 90%; margin: auto;">
            <pre><code class="language-bash" data-trim data-noescape>
4
0
3
1
9
2
6
5
7
8
            </code></pre>
          </div>
        </section>

        <section>
          <h2>OpenMP</h2>
          <p>By default, OpenMP often utilizes all available cores on the system by launching
          the same number of threads. You can control the number of threads used with an environment
          variable:</p>
          <div style="width: 90%; margin: auto;">
            <pre><code class="language-bash" data-trim data-noescape>
OMP_NUM_THREADS=4 ./a.out
            </code></pre>
          </div>
          <p class="fragment">If you set <code>OMP_NUM_THREADS=1</code> then it will carry out
          the loop serially in one single thread, without any parallelization.</p>
        </section>

        <section>
          <h2>OpenMP</h2>
          <p>OpenMP is often the go-to way to parallelize scientific programs in
          a shared-memory setting (e.g. a multi-core computer). Scientific programs often
            rely heavily on predictable <code>for</code> loops, which is where OpenMP
          excels.</p>
          <p class="fragment">Low level threading works the best with parallel tasks that may not be
            as simple as a <code>for</code> loop. For exampling, loading a large
            file in the background.</p>
        </section>

        <section>
          <h2>Race Conditions</h2>
          <p>When multiple threads access the same memory location, there is no guarantee
            which thread will access it first, making the outcome non-deterministic.</p>
          <div>
            <p>Ways to avoid race conditions include:</p>
            <ul>
              <li class="fragment">
                Manually ensure that each thread only accesses its own memory. For example,
                declaring an array of size <code>omp_get_num_threads()</code> and
                using the thread ID to access the correct memory location.
              </li>
              <li class="fragment">
                Use OpenMP's <code>critical</code> directive to ensure that only one thread
                can access a block of code at a time:
                <div style="width: 90%; margin: auto;">
                  <pre><code class="language-c++" data-trim data-noescape>
int n = 0;
#pragma omp parallel for
for (int i = 0; i < 10; i++) {
#pragma omp critical
  n += 1;
}
                  </code></pre>
                </div>
              </li>
            </ul>
          </div>
        </section>

        <section>
          <h2>A Few Tips on <code>git</code></h2>
          <p>For the group project 1, you will be using <code>git</code> to
          collaborate. The workflow for multiple collaborators is slightly
          different from your usual single-person workflow.</p>
        </section>

        <section>
          <h2>A Few Tips on <code>git</code></h2>
          <p>Always <code>git pull</code> before <code>git push</code>.</p>
          <div class="fragment">
            <p>Someone else might have pushed to the GitHub online repository.
            If that is true, you will not be allowed to push to it. You will
            first need to incorporate their commits to your own repository.</p>
            <p><code>VS Code</code> does this for you if you click on the
            "Synchronize" button.</p>
          </div>
        </section>

        <section>
          <h2>A Few Tips on <code>git</code></h2>
          <p>The first time you pull and there are other people's commits, you
            may see an error message from <code>git</code> not knowing how to
            handle it. You need to run one of the two following commands:</p>
          <ul>
            <li><code>git config --global pull.rebase false</code></li>
            <li><code>git config --global pull.rebase true</code></li>
          </ul>
          <div class="fragment">
          <p>The first option is usually the default behavior. Under this
          option, every time you pull someone else's commits while you have your
          own commits, a "merge" commit will be generated.</p>
          <p>The second option skips this merge commit, but conflict handling
            can be a bit more annoying. See a guide <a href="https://sakhawat-ali.medium.com/git-resolving-conflict-while-git-rebase-33b70ddb528e">here</a></p>
          </div>
        </section>

        <section>
          <h2>A Few Tips on <code>git</code></h2>
          <p>Try to work on different files, or different sections of the same file.</p>
          <div class="fragment">
            <p><code>git</code> is usually very good at figuring out who did
            what and merging those changes together. The exception is when two
              people changed the same line. Then <code>git</code> will have no
              idea whose version to use, and you will need to resolve the conflict by hand.</p>
            <p>Add the file after you solve the conflict, then commit it. It
            will generate a merge commit.</p>
          </div>
        </section>

        <section>
          <h2>Reach out if you have questions!</h2>
        </section>
      </div>
    </div>
    <!-- <script src="js/head.min.js"></script> -->
    <!-- <script>
         head.js(
         "vendor/jquery.min.js",
         // "vendor/three.js/build/three.min.js",
         // "vendor/three.js/examples/js/controls/OrbitControls.js",
         /* "vendor/socket.io-client/dist/socket.io.js", */
         // "vendor/THREE.MeshLine.js",
         /* "vendor/dat.gui.min.js",*/
         "vendor/EventEmitter.js",
         // "js/samples.js",
         );
         </script> -->
    <script src="../dist/reveal.js"></script>
    <script src="../plugin/math/math.js"></script>
    <script src="../plugin/notes/notes.js"></script>
    <script src="../plugin/markdown/markdown.js"></script>
    <script src="../plugin/highlight/highlight.js"></script>

    <script>
      // More info about initialization & config:
      // - https://revealjs.com/initialization/
      // - https://revealjs.com/config/
      Reveal.initialize({
        transition: "fade",
        slideNumber: true,
        history: true,
        center: true,
        width: "100%",
        height: "100%",
        disableLayout: false,
        navigationMode: "default",
        // minScale: 1,
        // maxScale: 1,
        margin: 0.2,
        padding: 0,
        hash: true,
        math: {
          mathjax: 'https://cdn.jsdelivr.net/gh/mathjax/mathjax@2.7.8/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          // pass other options into `MathJax.Hub.Config()`
          TeX: { Macros: { RR: "{\\bf R}" } }
        },
        // Learn about plugins: https://revealjs.com/plugins/
        plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath ]
      });
      Reveal.configure({
        keyboard: {
          81: null, // Do not respond to Q
          // 32: null, // Do not respond to space
        }
      });
      // Reveal.addEventListener("slidechanged", function(event) {
      //   var foot1 = document.getElementById("footer1");
      //   var foot2 = document.getElementById("footer2");
      //
      //   if (Reveal.getIndices().h === 0) {
      //     foot1.style.display = "none";
      //     foot2.style.display = "none";
      //   } else {
      //     foot1.style.display = "block";
      //     foot2.style.display = "block";
      //   }
      // });
      //
    </script>
  </body>
</html>
