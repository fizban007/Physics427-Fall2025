<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content=
      "width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Computational Physics Lecture 8</title>
    <link rel="stylesheet" href="../dist/reset.css">
    <link rel="stylesheet" href="../dist/reveal.css">
    <link rel="stylesheet" href="../dist/theme/serif.css"
      id="theme">
    <!-- <link rel="stylesheet" href="./dist/theme/night.css" id="theme"> -->
    <!-- Theme used for syntax highlighted code -->
    <link rel="stylesheet" href=
      "../plugin/highlight/monokai.css" id="highlight-theme">
    <link rel="stylesheet" href=
      "../css/style.css">
  </head>
  <body>
    <div class="reveal">
      <div class="slides">
        <section>
          <h2>Ordinary Differential Equations</h2>
        </section>

        <section>
          <h2>Review</h2>
          <p>Last week we discussed methods to solve ordinary differential equations (ODEs):
            $$
            \frac{d\mathbf{y}}{dx} = \mathbf{f}(x, \mathbf{y})
            $$</p>
          <p class="fragment">
            Both the left hand side and right hand side can be vectors. When we
            solve a system of $N$ coupled first-order ODEs, $\mathbf{y}$ and
            $\mathbf{f}$ are both $N$-dimensional vectors.
          </p>
          <ul class="fragment">
            <li>Euler integration</li>
            <li>Midpoint method</li>
            <li>4th order Runge-Kutta (RK4)</li>
            <li>Implicit Euler</li>
          </ul>
        </section>

        <section>
          <h2>Review</h2>
          <p>The Runge-Kutta family of methods can be summarized as the following prescription:
          $$
          \mathbf{y}_{n+1} = \mathbf{y}_n + h\sum_{i = 1}^{s}b_i \mathbf{k}_i
          $$
          </p>
          <div class="fragment">
            <p>where:</p>
            $$
            \mathbf{k}_i = \mathbf{f}\left(x_n + c_i h, \mathbf{y}_n + h \sum_{j=1}^{i-1}a_{ij}\mathbf{k}_j\right),\quad i = 1, 2, \ldots, s
            $$
            <p>where $s$ is the number of "stages" in the method. The method is
              completely specified by the coefficients $a_{ij}$, $b_i$, and $c_i$.</p>
          </div>
        </section>

        <section>
          <h2>Varying Step Size</h2>
          <p>As we discussed earlier, one drawback of RK4 is that it uses a
            fixed step size $h$, which needs to be chosen beforehand and cannot
            adapt to the problem on-the-fly.</p>
          <p class="fragment">Why is this considered a drawback?</p>
          <p class="fragment">Our goal now is to construct a version of RK4 that
            can adjust the step size on the fly, during the integration process.</p>
        </section>

        <section>
          <h2>Error Estimate for RK4</h2>
          <p>The simplest way to construct an adaptive method from RK4 is to
            take two trial "steps":</p>
          <p>The first one is the usual RK4 step with step size $h$,</p>
          <p>The second one consists of two substeps with sizes $h/2$.</p>
          $$
          \begin{align}
          y_{n+1}^{(1)} &= y_n + \mathrm{RK4}(h, x_n, y_n) \\
          y_{n+1/2}^{(2)} &= y_n + \mathrm{RK4}(h/2, x_n, y_n) \\
          y_{n+1}^{(2)} &= y_{n+1/2}^{(2)} + \mathrm{RK4}(h/2, x_n + h/2, y_{n+1/2}^{(2)})
          \end{align}
          $$
          <p>You can then estimate the error as $\varepsilon = |y^{(1)} - y^{(2)}|$.</p>
          <p class="fragment">How many evaluations of $f$ is required?</p>
        </section>

        <section>
          <h2>Error Estimate for RK4</h2>
          <p>How should $\varepsilon$ depend on $h$?</p>
          <div class="fragment">
            <p>Since RK4 is a 4th-order accurate method, its error is 5th order in $h$.</p>
            $$
            \begin{align}
            y(x_n + h) &= y^{(1)} + ch^5 + O(h^6) \\
            y(x_n + h) &= y^{(2)} + 2c(h/2)^5 + O(h^6)
            \end{align}
            $$
            <p>Therefore $\varepsilon = |y^{(1)} - y^{(2)}|$ also scales as $h^5$.</p>
          </div>
        </section>

        <section>
          <h2>From Error to Step Size</h2>
          <p>How should we choose the step size $h$?</p>
          <p>Since $\varepsilon \propto h^5$, we can write</p>
          $$
          \varepsilon = |y^{(1)} - y^{(2)}| = C h^5
          $$
          <p>where $C$ is a constant. If we have a desired error target
            $\varepsilon_\mathrm{target}$, how should we choose $h'$ for the
            next step such that $\epsilon$ becomes $\epsilon_\mathrm{target}$?</p>
          <div class="fragment">
            $$
            \frac{\varepsilon_\mathrm{target}}{h'^5} = \frac{\varepsilon}{h^5} = C,\quad h' = \left(\frac{\varepsilon_\mathrm{target}}{\varepsilon}\right)^{1/5} h
            $$
          </div>
        </section>

        <section>
          <h2>From Error to Step Size</h2>
          <p>How should we choose the desired error $\varepsilon_\mathrm{target}$?</p>
          <div class="fragment">
            <p>You might be thinking about specifying some tolerance. Since we
              know nothing about the unknown function $y(x)$, we need to be quite general:</p>
            $$
            \varepsilon_\mathrm{target} = \epsilon_\mathrm{abs} + \epsilon_\mathrm{rel} |y|
            $$
          </div>
          <div class="fragment">
            <p>But I have $y^{(1)}$ and $y^{(2)}$, which one should I use? It's
              a choice that you can make, e.g. always choose $y^{(1)}$.</p>
          </div>
        </section>

        <section>
          <h2>From Error to Step Size</h2>
          <p>What if you are solving multiple coupled equations for $y_i(x)$?</p>
          <p>Since $\varepsilon_\mathrm{target}$ depends on $y$, every
            component will in general have a different error target. But we only have one $h$.</p>
          <div class="fragment">
            <p>We define a norm of the error vector to obtain a scalar error:</p>
            $$
            \mathrm{err} = \sqrt{\frac{1}{N_\mathrm{eq}}\sum_{i=0}^{N_\mathrm{eq} - 1} \left(\frac{\varepsilon_i}{\varepsilon_\mathrm{target,i}}\right)^2}
            $$
            <p>We aim to have $\mathrm{err} \lesssim 1$.</p>
          </div>
        </section>

        <section>
          <h2>From Error to Step Size</h2>
          <p>Using the scalar $\mathrm{err}$, the step size control can be simply written as:</p>
          $$
          h' = S h \left(\frac{1}{\mathrm{err}}\right)^{1/5}
          $$
          <p>We have inserted a "safety factor" $S$ here. $S < 1$ since we don't want to
            overshoot the error. In practice $S = 0.9$ works quite well.</p>
        </section>

        <section>
          <h2>General Strategy</h2>
          <ol>
            <li class="fragment">Compute $y^{(1)}$ and $y^{(2)}$ using a single RK4 step of $h$
              and two RK4 steps of $h/2$. Remember $y$ might be a vector, especially when we solve multiple coupled equations at once.</li>
            <li class="fragment">Compute the error estimate $\varepsilon_i = |y_i^{(1)} - y_i^{(2)}|$ and target error $\varepsilon_\mathrm{target,i} = \epsilon_\mathrm{abs} + \epsilon_\mathrm{rel} |y_i|$.</li>
            <div class="fragment">
              <li>Compute the rescaled scalar error:</li>
              $$
              \mathrm{err} = \sqrt{\frac{1}{N_\mathrm{eq}}\sum_{i=0}^{N_\mathrm{eq} - 1} \left(\frac{\varepsilon_i}{\varepsilon_\mathrm{target,i}}\right)^2}
              $$
            </div>
            <li class="fragment">
              If $\mathrm{err} < 1$, accept the step and move forward by
              advancing $x\to x+h$. Otherwise, reject the step and try again.
              Either way, we can set $h' = Sh/(\mathrm{err})^{1/5}$. If $\mathrm{err}
              < 1$, this step will increase the step size at next step.
            </li>
          </ol>
        </section>

        <section>
          <h2>General Strategy</h2>
          <p>A few possible practical improvements to the strategy:</p>
          <ul>
            <li class="fragment">When the previous step size was rejected, do not increase the
              step size immediately afterwards.</li>
            <li class="fragment">An empirically more stable way to update the step size:
              $$
              h' = S h(\mathrm{err})^{-0.7/5}(\mathrm{err}_\mathrm{prev})^{0.4/5}
              $$
            </li>
            <li class="fragment">Use an "embedded" method to reduce the number of function evaluations at each step.</li>
            <li class="fragment">Use interpolation so that we have a uniform set of output points (dense output).</li>
          </ul>
        </section>

        <section>
          <h2>Adaptive RK4 Example</h2>
          <p>Let's look at an example</p>
          $$
          y(x) = \sin\left(e^{-x^2/a^2}\omega x\right)
          $$
          <p>The equation is:</p>
          $$
          \frac{dy}{dx} = e^{-x^2/a^2}\frac{a^2 - 2x^2}{a^2}\omega \cos\left(e^{-x^2/a^2}\omega x\right)
          $$
        </section>

        <section>
          <h2>Adaptive RK4 Example</h2>
          $a = 3$, $\omega = 20$<br>
          <img src="example-y.png" alt="y" width="60%">
        </section>

        <section>
          <h2>Adaptive RK4 Example</h2>
          $a = 3$, $\omega = 20$<br>
          <img src="example-compare.png" alt="y" width="60%">
        </section>

        <section>
          <h2>Adaptive RK4 Example</h2>
          $a = 3$, $\omega = 20$<br>
          <img src="example-h.png" alt="y" width="60%">
        </section>

        <section>
          <h2>Improving Efficiency</h2>
          <p>The naive adaptive RK4 method outlined last time requires 12
          evaluations of the function $f(x, y)$. It's often desirable to use
          fewer evaluations.</p>
          <p class="fragment">
            One way to achieve this is the so-called <em>embedded method</em>. The
            idea is to use a higher-order method to estimate the error, but
            without using additional evaluations of $f(x, y)$.
          </p>
        </section>

        <section>
          <h2>Embedded Methods</h2>
          <p>Embedded methods contain two bottom rows in their Butcher Tableau.
          The second row contains an estimate to the solution that is often 1 order
          lower, allowing an estimate of local truncation error</p>
          $$
          \begin{array}{c|cccccc}
          c_1 & & & & & &\\
          c_2 & a_{21} &  &  & & &\\
          c_3 & a_{31} & a_{32} &  & &  &\\
          c_4 & a_{41} & a_{42} & a_{43} & & & \\
          \vdots & \vdots & \vdots & \vdots & \ddots & & \\
          c_s & a_{s1} & a_{s2} & a_{s3} & \cdots & a_{s,s-1} & \\
          \hline
          & b_1 & b_2 & b_3 & \cdots & b_{s-1} & b_s \\
          & b_1^* & b_2^* & b_3^* & \cdots & b_{s-1}^* & b_s^*
          \end{array}
          $$
          <p class="fragment">
            The error estimate is then given by
            $$
            \varepsilon = |y_{n+1} - y_{n+1}^*| = h\sum_{i=1}^s (b_i - b_i^*)k_i
            $$
          </p>
        </section>

        <section>
          <h2>Order 5(4) Dormand-Prince</h2>
          <p>The Dormand-Prince method is a 5th order method with an embedded
            4th order method. The Butcher Tableau is</p>
          $$
          \begin{array}{c|ccccccc}
          0 & & & & & & &\\
          1/5 & 1/5 & & & & & &\\
          3/10 & 3/40 & 9/40 & & & & &\\
          4/5 & 44/45 & -56/15 & 32/9 & & & &\\
          8/9 & 19372/6561 & -25360/2187 & 64448/6561 & -212/729 & & &\\
          1 & 9017/3168 & -355/33 & 46732/5247 & 49/176 & -5103/18656 & &\\
          1 & 35/384 & 0 & 500/1113 & 125/192 & -2187/6784 & 11/84 &\\
          \hline
          & 35/384 & 0 & 500/1113 & 125/192 & -2187/6784 & 11/84 & 0\\
          & 5179/57600 & 0 & 7571/16695 & 393/640 & -92097/339200 & 187/2100 & 1/40
          \end{array}
          $$
          <p class="fragment">The first line below is accurate to order $O(h^5)$, while the
          second line is only accurate to order $O(h^4)$. This is the default method used
            by <code>Python</code>'s <code>solve_ivp</code>.</p>
        </section>

        <section>
          <h2>Order 5(4) Cash-Karp</h2>
          <p>The Cash-Karp method is another 5th order method with an embedded
            4th order method. The Butcher Tableau is</p>
          $$
          \begin{array}{c|cccccc}
          0 & & & & & &\\
          1/5 & 1/5 & & & & &\\
          3/10 & 3/40 & 9/40 & & & &\\
          3/5 & 3/10 & -9/10 & 6/5 & & &\\
          1 & -11/54 & 5/2 & -70/27 & 35/27 & &\\
          7/8 & 1631/55296 & 175/512 & 575/13824 & 44275/110592 & 253/4096 &\\
          \hline
          & 37/378 & 0 & 250/621 & 125/594 & 0 & 512/1771\\
          & 2825/27648 & 0 & 18575/48384 & 13525/55296 & 277/14336 & 1/4
          \end{array}
          $$
          <p class="fragment">The Cash-Karp method was mostly developed for semi-stiff problems,
          and behaves slightly better than Dormand-Prince in those scenarios.</p>
        </section>

        <section>
          <h2>Using an embedded Method</h2>
          <p>To use, e.g. the Dormand-Prince 5th order method in practice, you simply replace the first
          step in our strategy by the DP45 algorithm:</p>
          <div class="fragment">
            <p><s>Compute $y^{(1)}$ and $y^{(2)}$ using a single RK4 step of $h$ and two RK4 steps of $h/2$.</s></p>
            <p>Compute $y^{(1)}$ and $y^{(2)}$ using the two different rows of
            the DP45 Butcher Tableau.</p>
          </div>
          <p class="fragment">
            If $y^{(1)}$ is the 5th order estimate and $y^{(2)}$ is the 4th
            order, then you should always use $y^{(1)}$ to advance the solution,
            and use the difference between $y^{(1)}$ and $y^{(2)}$ to estimate
            the error.
          </p>
        </section>

        <section>
          <h2>Adaptive DP45</h2>
          <ol>
            <li class="fragment">Compute $y^{(1)}$ and $y^{(2)}$ using the two different rows of
            the DP45 Butcher Tableau. Remember $y$ might be a vector, especially when we solve multiple coupled equations at once.</li>
            <li class="fragment">Compute the error estimate $\varepsilon_i = |y_i^{(1)} - y_i^{(2)}|$ and target error $\varepsilon_\mathrm{target,i} = \epsilon_\mathrm{abs} + \epsilon_\mathrm{rel} |y_i^{(1)}|$.</li>
            <div class="fragment">
            <li>Compute the rescaled scalar error:</li>
            $$
            \mathrm{err} = \sqrt{\frac{1}{N_\mathrm{eq}}\sum_{i=0}^{N_\mathrm{eq} - 1} \left(\frac{\varepsilon_i}{\varepsilon_\mathrm{target,i}}\right)^2}
            $$
            </div>
            <li class="fragment">
              If $\mathrm{err} < 1$, accept the step and move forward by
              advancing $x\to x+h$. Otherwise, reject the step and try again.
              Either way, we can set $h' = Sh/(\mathrm{err})^{1/5}$. If $\mathrm{err}
              < 1$, this step will increase the step size at next step.
            </li>
          </ol>
        </section>

      </div>
    </div>
    <!-- <script src="js/head.min.js"></script> -->
    <!-- <script>
         head.js(
         "vendor/jquery.min.js",
         // "vendor/three.js/build/three.min.js",
         // "vendor/three.js/examples/js/controls/OrbitControls.js",
         /* "vendor/socket.io-client/dist/socket.io.js", */
         // "vendor/THREE.MeshLine.js",
         /* "vendor/dat.gui.min.js",*/
         "vendor/EventEmitter.js",
         // "js/samples.js",
         );
         </script> -->
    <script src="../dist/reveal.js"></script>
    <script src="../plugin/math/math.js"></script>
    <script src="../plugin/notes/notes.js"></script>
    <script src="../plugin/markdown/markdown.js"></script>
    <script src="../plugin/highlight/highlight.js"></script>

    <script>
      // More info about initialization & config:
      // - https://revealjs.com/initialization/
      // - https://revealjs.com/config/
      Reveal.initialize({
        transition: "fade",
        slideNumber: true,
        history: true,
        center: true,
        width: "100%",
        height: "100%",
        disableLayout: false,
        navigationMode: "default",
        // minScale: 1,
        // maxScale: 1,
        margin: 0.2,
        padding: 0,
        hash: true,
        math: {
          mathjax: 'https://cdn.jsdelivr.net/gh/mathjax/mathjax@2.7.8/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          // pass other options into `MathJax.Hub.Config()`
          TeX: { Macros: { RR: "{\\bf R}" } }
        },
        // Learn about plugins: https://revealjs.com/plugins/
        plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath ]
      });
      Reveal.configure({
        keyboard: {
          81: null, // Do not respond to Q
          // 32: null, // Do not respond to space
        }
      });
      // Reveal.addEventListener("slidechanged", function(event) {
      //   var foot1 = document.getElementById("footer1");
      //   var foot2 = document.getElementById("footer2");
      //
      //   if (Reveal.getIndices().h === 0) {
      //     foot1.style.display = "none";
      //     foot2.style.display = "none";
      //   } else {
      //     foot1.style.display = "block";
      //     foot2.style.display = "block";
      //   }
      // });
      //
    </script>
  </body>
</html>
